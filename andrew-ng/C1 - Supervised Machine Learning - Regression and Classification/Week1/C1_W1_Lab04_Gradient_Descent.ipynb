{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d455e5ef",
   "metadata": {},
   "source": [
    "# Gradient Descent for Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0eea0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('./deeplearning.mplstyle')\n",
    "from lab_utils_uni import plt_house_x, plt_contour_wgrad, plt_divergence, plt_gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972af670",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "| Size (1000 sqft)     | Price (1000s of dollars) |\n",
    "| ----------------| ------------------------ |\n",
    "| 1               | 300                      |\n",
    "| 2               | 500                      |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2687bf1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: [1. 2.], y_train: [300. 500.]\n"
     ]
    }
   ],
   "source": [
    "# Load our dataset\n",
    "x_train  = np.array([1.0, 2.0])\n",
    "y_train  = np.array([300.0, 500.0])\n",
    "\n",
    "print(f\"x_train: {x_train}, y_train: {y_train}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ddaa4c",
   "metadata": {},
   "source": [
    "## Compute cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "581b850e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(x_train, y_train, w, b):\n",
    "    # Number of features:\n",
    "    m = x_train.shape[0]\n",
    "    cost = 0\n",
    "    for i in range(m):\n",
    "        f_wb = w*x_train[i] + b\n",
    "        cost = cost + (f_wb - y_train[i])**2\n",
    "\n",
    "    return (1 / (2*m)) * cost "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35dddc2",
   "metadata": {},
   "source": [
    "<a name=\"toc_40291_2.1\"></a>\n",
    "## Gradient descent summary\n",
    "So far in this course, you have developed a linear model that predicts $f_{w,b}(x^{(i)})$:\n",
    "$$\n",
    "f_{w,b}(x^{(i)}) = wx^{(i)} + b \\tag{1}\n",
    "$$\n",
    "In linear regression, you utilize input training data to fit the parameters $w$,$b$ by minimizing a measure of the error between our predictions $f_{w,b}(x^{(i)})$ and the actual data $y^{(i)}$. The measure is called the $cost$, $J(w,b)$. In training you measure the cost over all of our training samples $x^{(i)},y^{(i)}$\n",
    "$$\n",
    "J(w,b) = \\frac{1}{2m} \\sum\\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)})^2 \\tag{2}\n",
    "$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb65e33b",
   "metadata": {},
   "source": [
    "\n",
    "In lecture, *gradient descent* was described as:\n",
    "\n",
    "$$\\begin{align*} \\text{repeat}&\\text{ until convergence:} \\; \\lbrace \\newline\n",
    "\\;  w &= w -  \\alpha \\frac{\\partial J(w,b)}{\\partial w} \\tag{3}  \\; \\newline \n",
    " b &= b -  \\alpha \\frac{\\partial J(w,b)}{\\partial b}  \\newline \\rbrace\n",
    "\\end{align*}$$\n",
    "where, parameters $w$, $b$ are updated simultaneously.  \n",
    "The gradient is defined as:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial J(w,b)}{\\partial w}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)})x^{(i)} \\tag{4}\\\\\n",
    "  \\frac{\\partial J(w,b)}{\\partial b}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)}) \\tag{5}\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Here *simultaniously* means that you calculate the partial derivatives for all the parameters before updating any of the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f477f727",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569e77c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6a17ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d593335a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99231fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89505470",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbd6a6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fef543",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_sgu_ml_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
