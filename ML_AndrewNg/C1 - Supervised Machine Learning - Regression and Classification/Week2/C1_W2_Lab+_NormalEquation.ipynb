{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68a3ffb3",
   "metadata": {},
   "source": [
    "## Bối cảnh\n",
    "\n",
    "Bài toán **Linear Regression**:\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "$ \n",
    "\\hat{y} = \\mathbf{w}^\\top \\mathbf{x} + b \n",
    "$\n",
    "\n",
    "</div>\n",
    "\n",
    "Mục tiêu: tìm $ \\mathbf{w}, b $ sao cho hàm mất mát (MSE) nhỏ nhất:\n",
    "<div align=\"center\">\n",
    "\n",
    "$\n",
    "J(\\mathbf{w}, b) = \\frac{1}{2m} \\sum_{i=1}^m \\Big( \\hat{y}^{(i)} - y^{(i)} \\Big)^2\n",
    "$\n",
    "\n",
    "</div>\n",
    "\n",
    "Trong đó:\n",
    "- $ m $: số lượng mẫu huấn luyện\n",
    "- $ \\mathbf{x}^{(i)} $: vector đặc trưng (feature vector) của mẫu thứ $ i $\n",
    "- $ y^{(i)} $: giá trị thực tế (ground truth)\n",
    "- $ \\hat{y}^{(i)} $: giá trị dự đoán\n",
    "\n",
    "Với **Gradient Descent**, ta cập nhật $ \\mathbf{w}, b $ lặp đi lặp lại cho đến khi hội tụ.\n",
    "\n",
    "Với **Normal Equation**, ta có thể tìm được nghiệm tối ưu trực tiếp (không cần lặp).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303fc108",
   "metadata": {},
   "source": [
    "## Biểu diễn bằng ma trận\n",
    "\n",
    "Gộp $b$ vào $\\mathbf{w}$ bằng cách thêm một cột $1$ vào $\\mathbf{X}$:  \n",
    "\n",
    "$$\n",
    "\\mathbf{X} =\n",
    "\\begin{bmatrix}\n",
    "1 & x_1^{(1)} & x_2^{(1)} & \\cdots & x_n^{(1)} \\\\\n",
    "1 & x_1^{(2)} & x_2^{(2)} & \\cdots & x_n^{(2)} \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "1 & x_1^{(m)} & x_2^{(m)} & \\cdots & x_n^{(m)}\n",
    "\\end{bmatrix},\n",
    "\\quad\n",
    "\\mathbf{w} =\n",
    "\\begin{bmatrix}\n",
    "b \\\\ w_1 \\\\ w_2 \\\\ \\vdots \\\\ w_n\n",
    "\\end{bmatrix},\n",
    "\\quad\n",
    "\\mathbf{y} =\n",
    "\\begin{bmatrix}\n",
    "y^{(1)} \\\\ y^{(2)} \\\\ \\vdots \\\\ y^{(m)}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Hàm dự đoán được viết gọn:  \n",
    "\n",
    "$$\n",
    "\\hat{\\mathbf{y}} = \\mathbf{X}\\mathbf{w}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a29d045",
   "metadata": {},
   "source": [
    "## &rarr; Normal Equation\n",
    "\n",
    "Nghiệm tối ưu của **w** được cho bởi công thức **Normal Equation**:  \n",
    "\n",
    "$$\n",
    "\\mathbf{w} = (X^{T}X)^{-1}X^{T}y\n",
    "$$\n",
    "\n",
    "**Ý nghĩa:**\n",
    "\n",
    "- \\(X^{T}X\\): ma trận vuông kích thước \\((n+1) \\times (n+1)\\)\n",
    "- Nếu khả nghịch, ta lấy nghịch đảo để tìm nghiệm tối ưu\n",
    "- Đây là nghiệm tối ưu (minimizing MSE) **một lần duy nhất**, không cần Gradient Descent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be89018d",
   "metadata": {},
   "source": [
    "## ⚖️ So sánh với Gradient Descent\n",
    "\n",
    "| Tiêu chí | **Gradient Descent** | **Normal Equation** |\n",
    "|---------|----------------|----------------|\n",
    "| **Cách tìm nghiệm** | Lặp dần đến khi hội tụ | Công thức đóng (closed-form), tính một lần |\n",
    "| **Tốc độ** | Chậm khi số vòng lặp nhiều, nhưng mở rộng tốt cho dữ liệu lớn | Nhanh khi số feature nhỏ(<10.000), chậm nếu phải nghịch đảo ma trận lớn |\n",
    "| **Độ phức tạp tính toán** | \\(O(mn)\\) mỗi vòng lặp (m = số mẫu, n = số feature) | \\(O(n^3)\\) để tính nghịch đảo |\n",
    "| **Thích hợp khi** | n rất lớn (hàng triệu feature) | n nhỏ đến vừa |\n",
    "| **Learning rate** | Cần chọn cẩn thận | Không cần |\n",
    "| **Kết quả** | Xấp xỉ (cần hội tụ) | Chính xác (nếu ma trận khả nghịch) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfc760a",
   "metadata": {},
   "source": [
    "## Implement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c63c8dc",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{w} =\n",
    "\\begin{bmatrix}\n",
    "b \\\\ w \\\\ \n",
    "\\end{bmatrix} \n",
    "= (X^{T}X)^{-1}X^{T}y\n",
    "\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0983628e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w = [100. 200.]\n"
     ]
    }
   ],
   "source": [
    "# Dữ liệu thực tế từ Gradient Descent (Houses Prices)\n",
    "import numpy as np\n",
    "\n",
    "# Simulation data\n",
    "X = np.array([[1, 1],\n",
    "              [1, 2]])  # cột 1 = bias term(cho b), cột 2 = x\n",
    "y = np.array([300.0, 500.0])\n",
    "\n",
    "# Normal Equation\n",
    "w = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "\n",
    "# b = 0.8333    (intercept)\n",
    "# w1 = 0.75 \n",
    "print(f\"w = {w}\")   # [b, w1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e92215c",
   "metadata": {},
   "source": [
    "- Mô hình dự đoán (Houses Prices)\n",
    "$$\n",
    "\\hat{\\mathbf{y}} = 100\\mathbf{w} + 200\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d98a433",
   "metadata": {},
   "source": [
    "### The end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_sgu_ml_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
